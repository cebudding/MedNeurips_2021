{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network and training VGG inspired net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import h5py\n",
    "\n",
    "plt.rc('image', cmap='gist_gray')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import keras\n",
    "from keras.utils import Sequence\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.layers import Flatten, Activation\n",
    "\n",
    "from classification_models import Classifiers\n",
    "\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tf', tf.__version__)\n",
    "print('keras', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/path/to/working/dir'\n",
    "data_dir = os.path.join(path, 'data_folder')\n",
    "result_dir = os.path.join(path, 'results_folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = \"6\"\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load + preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_h5 = h5py.File(os.path.join(data_dir, 'training_data.h5'), 'r')\n",
    "val_h5 = h5py.File(os.path.join(data_dir, 'val_data.h5'), 'r')\n",
    "holdout_h5 = h5py.File(os.path.join(data_dir, 'holdout_data.h5'), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train_binary = train_h5['X'], train_h5['y']\n",
    "X_val, y_val_binary = val_h5['X'], val_h5['y']\n",
    "X_holdout, y_holdout_binary = holdout_h5['X'], holdout_h5['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train), len(X_val), len(X_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train_binary, num_classes=2)[:42000]\n",
    "y_val = keras.utils.to_categorical(y_val_binary, num_classes=2)[:6000]\n",
    "y_holdout = keras.utils.to_categorical(y_holdout_binary, num_classes=2)[:12000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12, 8))\n",
    "for i in range(5): \n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(X_train[25 + i])\n",
    "    plt.title(y_train[25 + i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train[:42000])\n",
    "X_val = np.array(X_val[:6000])\n",
    "X_holdout = np.array(X_holdout[:12000])\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_holdout = np.array(y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X_train) == len(y_train)\n",
    "assert len(X_val) == len(y_val)\n",
    "assert len(X_holdout) == len(y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_float(x, is_3d_mri=True):\n",
    "    \"\"\" \n",
    "    Function that performs max-division normalization on a `numpy.ndarray` \n",
    "    matrix. \n",
    "    \"\"\"\n",
    "    if is_3d_mri:\n",
    "        assert(len(x.shape) >= 4)\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i] /= np.max(x[i])\n",
    "    return x\n",
    "\n",
    "\n",
    "class IntensityRescale:\n",
    "    \"\"\"\n",
    "    Rescale image itensities between 0 and 1 for a single image.\n",
    "    Arguments:\n",
    "        masked: applies normalization only on non-zero voxels. Default\n",
    "            is True.\n",
    "        on_gpu: speed up computation by using GPU. Requires torch.Tensor\n",
    "             instead of np.array. Default is False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, masked=True, on_gpu=False):\n",
    "        self.masked = masked\n",
    "        self.on_gpu = on_gpu\n",
    "\n",
    "    def __call__(self, image):\n",
    "        if self.masked:\n",
    "            image = self.zero_masked_transform(image)\n",
    "        else:\n",
    "            image = self.apply_transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def apply_transform(self, image):\n",
    "        if self.on_gpu:\n",
    "            return normalize_float_torch(image)\n",
    "        else:\n",
    "            return normalize_float(image, is_3d_mri = False)\n",
    "\n",
    "    def zero_masked_transform(self, image):\n",
    "        \"\"\" Only apply transform where input is not zero. \"\"\"\n",
    "        img_mask = image == 0\n",
    "        # do transform\n",
    "        image = self.apply_transform(image)\n",
    "        image[img_mask] = 0.\n",
    "        return image\n",
    "\n",
    "def sagittal_flip(batch):\n",
    "    \"\"\" \n",
    "        Expects shape (None, X, Y, Z, C).\n",
    "        Flips along the X axis (sagittal).\n",
    "        \n",
    "    \"\"\"\n",
    "    thresh = 0.5\n",
    "    batch_augmented = np.zeros_like(batch)\n",
    "    for idx in range(len(batch)):\n",
    "        rand = np.random.uniform()\n",
    "        if rand > thresh:\n",
    "            batch_augmented[idx] = np.flip(batch[idx], axis=0)\n",
    "        else:\n",
    "            batch_augmented[idx] = batch[idx]\n",
    "    return batch_augmented\n",
    "\n",
    "def translate(batch):\n",
    "    \"\"\" \n",
    "        Expects shape (None, X, Y, Z, C).\n",
    "        Translates the X axis.\n",
    "    \"\"\"\n",
    "    batch_augmented = np.zeros_like(batch)\n",
    "    for idx in range(len(batch)):\n",
    "        rand = np.random.randint(-2, 3)\n",
    "        if rand < 0:\n",
    "            batch_augmented[idx,-rand:] = batch[idx,:rand]\n",
    "        elif rand > 0:\n",
    "            batch_augmented[idx,:-rand] = batch[idx,rand:]\n",
    "        else:\n",
    "            batch_augmented[idx] = batch[idx]\n",
    "    return batch_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity = IntensityRescale(masked = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Sequence):\n",
    "    def __init__(self, X, y, transform = None, batch_size = 32, shuffle = True, mask = None):\n",
    "        self.X = X\n",
    "        self.y = y \n",
    "        self.transform = transform \n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.mask = mask \n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.y)/self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = np.expand_dims(self.X[idx * self.batch_size:(idx + 1) * self.batch_size], 3)\n",
    "        label = np.array(self.y[idx * self.batch_size:(idx + 1) * self.batch_size], dtype=np.int8)\n",
    "        \n",
    "        if self.mask is not None: \n",
    "            for i in range(image.shape[0]):\n",
    "                image[i] *= self.mask\n",
    "        \n",
    "        for transformation in self.transform: \n",
    "            image = transformation(image)\n",
    "            \n",
    "        return image, label\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.X, self.y = shuffle(self.X, self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(X = X_train, y = y_train, batch_size = 8, shuffle = True, transform = [intensity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        if(logs.get('val_loss') < LOSS_THRESHOLD):   \n",
    "            print(f\"\\nReached below {LOSS_THRESHOLD} val loss, so stopping training!!\")   \n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Think about networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimpleModel(input_shape, drop_rate = 0, weight_dcay = 0):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-5\n",
    "num_epochs = 125 # If using fully artificial data -> set to 75, sufficient for training\n",
    "num_trials = 3  \n",
    "batch_size = 128\n",
    "store_models = True\n",
    "patience = 10 \n",
    "min_delta = 5e-4\n",
    "LOSS_THRESHOLD = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "max_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_trials):\n",
    "    print('Trial %i' %i)\n",
    "    model = SimpleModel(input_shape = (input_shape[0], input_shape[1], 1))\n",
    "    opt = keras.optimizers.SGD(lr = lr, momentum = 0.9)\n",
    "    model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    earlystop = EarlyStopping(monitor='val_loss', min_delta=min_delta, patience=patience, verbose=1, mode='auto')\n",
    "    stop_training = myCallback()\n",
    "    \n",
    "    if store_models:\n",
    "        result_path = os.path.join(result_dir, f\"best_weights_trial_{i}.hdf5\")\n",
    "        model_checkpoint = ModelCheckpoint(result_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max', save_weights_only=True)\n",
    "        callbacks = [earlystop, model_checkpoint, stop_training]\n",
    "    else:\n",
    "        callbacks = [earlystop, stop_training]\n",
    "        \n",
    "    train_loader = DataLoader(X_train, y_train, transform=[intensity], batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(X_val, y_val, transform=[intensity], batch_size=32, shuffle=False)\n",
    "    \n",
    "    history = model.fit_generator(train_loader,\n",
    "                        epochs=num_epochs,\n",
    "                        validation_data=val_loader,\n",
    "                        callbacks=callbacks)\n",
    "    \n",
    "    plt.figure(figsize=(11, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[\"loss\"], label = 'train')\n",
    "    plt.plot(history.history[\"val_loss\"], label = 'val')\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[\"acc\"], label = 'train')\n",
    "    plt.plot(history.history[\"val_acc\"], label = 'val')\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.show()\n",
    "    \n",
    "    y_pred = model.predict_generator(val_loader)\n",
    "    \n",
    "    # Store results\n",
    "    accuracies.append(history.history[\"val_acc\"][-1])\n",
    "    max_acc.append(np.max(history.history[\"val_acc\"]))\n",
    "    \n",
    "training_time = time.time() - start_time \n",
    "print(\"Training Time: {}h:{}m:{}s\".format(training_time//3600, (training_time//60)%60, training_time%60))\n",
    "\n",
    "print(\"Validation final accuracies: \\n {}\".format(accuracies))\n",
    "print(\"Validation final accuracies mean: {}\".format(np.mean(accuracies)))\n",
    "print(\"Validation best accuracies: \\n {}\".format(max_acc))\n",
    "print(\"Validation best accuracies mean: {}\".format(np.mean(max_acc)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\"best_weights_trial_0.hdf5\", \"best_weights_trial_1.hdf5\", \"best_weights_trial_2.hdf5\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(X_holdout, y_holdout, transform=[intensity], batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "\n",
    "for fold, weight in enumerate(weights):\n",
    "    print(\"Fold {}\".format(fold))\n",
    "    model = SimpleModel(input_shape = (input_shape[0], input_shape[1], 1))\n",
    "    model_dir = os.path.join(result_dir, weight)\n",
    "    model.load_weights(model_dir)\n",
    "    \n",
    "    opti = keras.optimizers.Adam(lr=lr)\n",
    "    model.compile(optimizer=opti,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    # Evaluate\n",
    "    res = model.evaluate_generator(test_loader)\n",
    "    y_pred = model.predict_generator(test_loader)\n",
    "  \n",
    "    # Store results\n",
    "    accuracies.append(res[1])\n",
    "\n",
    "    # Print results\n",
    "    print(\"Model accuracy {:.2f} %\".format(res[1]*100))\n",
    "    \n",
    "print(\"######## Final results ########\")\n",
    "print(\"Accuracy mean {:.2f} %\".format(np.mean(accuracies)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = time.time() - start_time\n",
    "print(\"Total time elapsed: {}h:{}m:{}s\".format(\n",
    "            total_time//3600, (total_time//60)%60, total_time%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
